{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9c89b0-9395-4e7c-a74e-c81e1388c1cb",
   "metadata": {},
   "source": [
    "Twitter Categorizer Project\n",
    "\n",
    "Problem: \n",
    "Twitter is a popular online social networking platform that allows users to post texts as “tweets.” Hashtags can group similar tweets and link to other tweets that include them, however, if a user doesn’t provide hashtags, it is hard to label a given tweet.\n",
    "\n",
    "Objective:\n",
    "This project aims to correctly categorize user-provided tweets by utilizing Big Data tools and ML techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a1225-1af3-41f2-9c17-254525547473",
   "metadata": {},
   "source": [
    "Process: \n",
    "- Collect and clean data from various sources \n",
    "- Harvard Dataverse, Kaggle, etc.\n",
    "- Load data to MongoDB and import data to Spark\n",
    "- Perform text-preprocessing (Remove special characters, stopwords, TF-IDF vectorize)\n",
    "- Implement a classification model to categorize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b082a533-6cb7-4e98-84f4-c714157158c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in ./Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d52978-8593-4515-953b-9070baf8538a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sparknlp\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, RegexTokenizer\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from nltk.corpus import stopwords\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17836be-a7d1-44f0-942d-99dccdd0831c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/26 11:55:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://seungui-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd8477c6370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "eec5192c-5f30-4c1f-914d-a182309442a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = spark.read.format(\"csv\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .load(\"combined_tweets.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7c945604-b49f-45f2-a2d3-d480c08ca7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4565e33c-ef7d-4f83-aa74-8b0715f1ce3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Username: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Tweets: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "66e1c871-5a19-4db9-b94f-01fc5e64e6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/26 12:43:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Username, ID, Tweets, Date, Label\n",
      " Schema: _c0, Username, ID, Tweets, Date, Label\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/seungpang/combined_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3161</td>\n",
       "      <td>sports_user</td>\n",
       "      <td>3161.0</td>\n",
       "      <td>Its time for world cup</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#WorldCup #WorldCup2022 #WorldcupQatar2022 #Qa...</td>\n",
       "      <td>2022-11-20 17:08:39+00:00</td>\n",
       "      <td>sports</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4453</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>Looks like @Tesla is/will be holding some spec...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Enjoy a complimentary ice cream with your fri...</td>\n",
       "      <td>2022-08-06 00:36:53+00:00</td>\n",
       "      <td>stocks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32374</td>\n",
       "      <td>Figgimus Maximus</td>\n",
       "      <td>253958386.0</td>\n",
       "      <td>Basically true. https://t.co/0vSbFCOp8k</td>\n",
       "      <td>2017-08-17 07:22:07</td>\n",
       "      <td>crypto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _c0  \\\n",
       "0                                               3161   \n",
       "1  #WorldCup #WorldCup2022 #WorldcupQatar2022 #Qa...   \n",
       "2                                               4453   \n",
       "3  “Enjoy a complimentary ice cream with your fri...   \n",
       "4                                              32374   \n",
       "\n",
       "                    Username           ID  \\\n",
       "0                sports_user       3161.0   \n",
       "1  2022-11-20 17:08:39+00:00       sports   \n",
       "2                       TSLA       3454.0   \n",
       "3  2022-08-06 00:36:53+00:00       stocks   \n",
       "4           Figgimus Maximus  253958386.0   \n",
       "\n",
       "                                              Tweets                 Date  \\\n",
       "0                             Its time for world cup                 None   \n",
       "1                                               None                 None   \n",
       "2  Looks like @Tesla is/will be holding some spec...                 None   \n",
       "3                                               None                 None   \n",
       "4            Basically true. https://t.co/0vSbFCOp8k  2017-08-17 07:22:07   \n",
       "\n",
       "    Label  \n",
       "0    None  \n",
       "1    None  \n",
       "2    None  \n",
       "3    None  \n",
       "4  crypto  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "78d0f242-1f4a-4a8d-9940-2472aee3d41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select necessary columns - Tweets, Label\n",
    "data = data.select(\"Tweets\", \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "14503f17-c319-4b62-9384-49beaea2d7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72211, 2)\n"
     ]
    }
   ],
   "source": [
    "#Check data shape\n",
    "print((data.count(), len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "49e21888-e57b-4250-978a-fc9b0cc77baf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Tweets|Label|\n",
      "+------+-----+\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "|  null| null|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check null values\n",
    "from pyspark.sql.functions import col\n",
    "data.filter(col(\"Tweets\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "813dd17b-241d-4be2-9559-0786225b0c44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Tweets|Label|\n",
      "+------+-----+\n",
      "| 30723|30723|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "df2 = data.select([count(when(col(\"Tweets\").contains('None') | \\\n",
    "                            col(\"Tweets\").contains('NULL') | \\\n",
    "                            (col(\"Tweets\") == '' ) | \\\n",
    "                            col(\"Tweets\").isNull() | \\\n",
    "                            isnan(\"Tweets\"), \"Tweets\" \n",
    "                           )).alias(c)\n",
    "                    for c in data.columns])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7b79ffca-0a13-431f-89b8-7a17039ecefd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Replace null values\n",
    "data = data.na.fill(\"this is null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "20529851-cddc-41fe-90cd-c20baadd7e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72211, 2)\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "print((data.count(), len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a987f304-e660-4470-915e-4053b5d9d287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check for data with correct label\n",
    "correct_label=[\"celebrity\",\"crypto\",\"stocks\",\"sports\",\"politics\"]\n",
    "data=data.filter(data.Label.isin(correct_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "35ab341f-4f76-4650-bdc4-3da7bbc970bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29001, 2)\n"
     ]
    }
   ],
   "source": [
    "print((data.count(), len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "004b0f97-7c7b-4669-95d2-05f1d3e8df9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweets: string (nullable = false)\n",
      " |-- Label: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "42d4b5a3-6460-4a81-a85a-f876489ab096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split into training and test\n",
    "(df_train, df_test) = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "72dab5ca-51dd-4cfa-a0b3-12628ad44fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweets: string (nullable = false)\n",
      " |-- Label: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1ba7c72b-1df4-440f-b865-148f34f965c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Regex Tokenize - Removes punctuation\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Tweets\", outputCol=\"regex\", pattern=\"\\W+\")\n",
    "regexTokenized = regexTokenizer.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3582b3d8-19b4-44fb-9027-aa7a205c1f68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|              Tweets| Label|               regex|\n",
      "+--------------------+------+--------------------+\n",
      "| ET5 delivery wil...|stocks|[et5, delivery, w...|\n",
      "|         Hyderabad.\"|sports|         [hyderabad]|\n",
      "| and $14.9K per s...|stocks|[and, 14, 9k, per...|\n",
      "| and why the comp...|stocks|[and, why, the, c...|\n",
      "| avoiding 400k to...|stocks|[avoiding, 400k, ...|\n",
      "+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3ed34935-ffa0-4cf5-9488-db5ba93d9223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Stop Words Remove\n",
    "remover = StopWordsRemover(inputCol=\"regex\", outputCol=\"Cleaned_Words\")\n",
    "clean_df = remover.transform(regexTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6ec5756e-d9a0-44c7-b124-9905a2bdd705",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+\n",
      "|              Tweets| Label|               regex|       Cleaned_Words|\n",
      "+--------------------+------+--------------------+--------------------+\n",
      "| ET5 delivery wil...|stocks|[et5, delivery, w...|[et5, delivery, t...|\n",
      "|         Hyderabad.\"|sports|         [hyderabad]|         [hyderabad]|\n",
      "| and $14.9K per s...|stocks|[and, 14, 9k, per...|[14, 9k, per, sec...|\n",
      "| and why the comp...|stocks|[and, why, the, c...|[company, correct...|\n",
      "| avoiding 400k to...|stocks|[avoiding, 400k, ...|[avoiding, 400k, ...|\n",
      "+--------------------+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b2582ae4-75b4-4f58-b753-5f0075eb0f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tf-idf vectorizer\n",
    "hashingTF = HashingTF(inputCol=\"Cleaned_Words\", outputCol=\"rawfeatures\",numFeatures=50)\n",
    "featurizedData = hashingTF.transform(clean_df)\n",
    "\n",
    "idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "df_train_tfidf = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "58618337-3b0d-4293-b88b-1c6206efb008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Index Label\n",
    "string_indexer = StringIndexer(inputCol='Label', outputCol='Label_Indexed')\n",
    "string_indexer_model = string_indexer.fit(df_train_tfidf)\n",
    "df_train_final = string_indexer_model.transform(df_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d50d41aa-abb4-4c7f-8ea2-c0d4b07ed2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------+--------------------+----------+\n",
      "|       Cleaned_Words|    Label|Label_Indexed|         probability|prediction|\n",
      "+--------------------+---------+-------------+--------------------+----------+\n",
      "|[lot, tech, growt...|   stocks|          3.0|[0.81269633939627...|       0.0|\n",
      "|[including, stron...|   stocks|          3.0|[0.42013330737820...|       1.0|\n",
      "|[patience, https,...|   stocks|          3.0|[0.58706633731306...|       0.0|\n",
      "|[much, still, bet...|   stocks|          3.0|[0.59512927151548...|       0.0|\n",
      "|[https, co, zq3h6...|   crypto|          1.0|[0.57546092735675...|       0.0|\n",
      "|[https, co, 1bszp...|   crypto|          1.0|[0.51041619335389...|       0.0|\n",
      "|[https, co, grspb...|   crypto|          1.0|[0.47677987931319...|       0.0|\n",
      "|[estreno, mundial...|celebrity|          0.0|[0.88801349257671...|       0.0|\n",
      "|[abd, nin, charlo...|   crypto|          1.0|[0.20118143464386...|       1.0|\n",
      "|[charlottesville,...|   crypto|          1.0|[0.04834071097010...|       1.0|\n",
      "+--------------------+---------+-------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Accuracy :  0.6891776372029407\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "LR_Model = LogisticRegression(featuresCol=idf.getOutputCol(), labelCol=string_indexer_model.getOutputCol())\n",
    "lr_model = LR_Model.fit(df_train_final)\n",
    "\n",
    "# Transform the test set \n",
    "df_test_token = regexTokenizer.transform(df_test)\n",
    "df_test_stopwords = remover.transform(df_test_token)\n",
    "df_test_tf = hashingTF.transform(df_test_stopwords)\n",
    "df_test_tfidf = idfModel.transform(df_test_tf)\n",
    "df_test_final= string_indexer_model.transform(df_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b45c1-13eb-4333-a153-d3374f10c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "prediction = lr_model.transform(df_test_final)\n",
    "prediction = prediction.na.drop()\n",
    "prediction.select(\"Cleaned_Words\", \"Label\", \"Label_Indexed\", \"probability\", \"prediction\").show(10)\n",
    "\n",
    "#Accuracy\n",
    "accuracy = prediction.filter(prediction.Label_Indexed == prediction.prediction).count() / float(prediction.count())\n",
    "print(\"Accuracy : \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4db26e-9b9d-42c1-80ff-209096e682ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
